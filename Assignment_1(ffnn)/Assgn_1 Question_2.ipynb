{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assgn_1/Question_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMQzg09DYHvA3Vz7287rm3j"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"C-J_lzBA4lBb"},"source":["# solution by Sayan Chandra CS20M057\r\n","# CS6910-DEEP LEARNING- (prof.) Mitesh M. Khapra"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXyA7hyhBi-1","executionInfo":{"status":"ok","timestamp":1615464099231,"user_tz":-330,"elapsed":3629,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}}},"source":["import matplotlib.pyplot as plt\r\n","from keras.datasets import fashion_mnist, mnist\r\n","import numpy as np\r\n","from copy import deepcopy as clone\r\n","\r\n","\r\n","from sklearn.datasets import make_blobs\r\n","data, lables = make_blobs(n_samples=10000, centers=2, n_features=5, random_state=0)\r\n","\r\n","\r\n","# load dataset"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLx8C3pGBRU-","executionInfo":{"status":"ok","timestamp":1615464102612,"user_tz":-330,"elapsed":1461,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}}},"source":["\r\n","def loadData():\r\n","    (trainX, trainy), (testX, testy) = fashion_mnist.load_data()\r\n","    N_inputs, dim_x_inp, dim_y_inp=len(trainX), len(trainX[0]), len(trainX[0][0])\r\n","    inputs=np.zeros((N_inputs, dim_x_inp*dim_y_inp))\r\n","    sum1=np.zeros((dim_x_inp*dim_y_inp))\r\n","    for i in range(N_inputs):\r\n","       inputs[i]=trainX[i].flatten()\r\n","       sum1+=inputs[i]\r\n","    mean1=sum1/N_inputs\r\n","    dim_inp=inputs.shape[1]\r\n","\r\n","    sum2=np.zeros((dim_x_inp*dim_y_inp))\r\n","    testx=np.zeros((len(testX), dim_x_inp*dim_y_inp))\r\n","    for i in range(len(testX)):\r\n","      testx[i]=testX[i].flatten()\r\n","      sum2+=testx[i]\r\n","    mean2=sum2/len(testX)\r\n","\r\n","    for i in range(N_inputs):\r\n","      inputs[i]-=mean1\r\n","      inputs[i]/=255\r\n","    trainx=inputs\r\n","\r\n","    for i in range(len(testX)):\r\n","      testx[i]-=mean2\r\n","      testx[i]/=255\r\n","    return (trainx[6000: ], trainy[6000:], trainx[:6000], trainy[:6000], testx, testy)\r\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7mDtmXI6BTnz","executionInfo":{"status":"ok","timestamp":1615464107832,"user_tz":-330,"elapsed":3227,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}},"outputId":"69231a76-0d8a-4c6b-f07a-366ef07cfc12"},"source":["trainx, trainy, valx, valy, testx, testy=loadData()\r\n","dim_inp=trainx.shape[1]"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_ydmTBQ5RTv","executionInfo":{"status":"ok","timestamp":1615464145835,"user_tz":-330,"elapsed":1097,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}},"outputId":"b1dbe47c-38cd-41ed-cf27-dddcca63a9af"},"source":["\r\n","\r\n","## main variables inputs matrix, N_inputs, dim_inp\r\n","\r\n","class MLSN (object): ## Multi layer Sigmoid Neurons\r\n","  def __init__(self, szInp, hiddenL, numOp, actvfunc, initfunc, lossfunc, lmda, vx, vy, xtest, ytest) :## size of inp, num of hidden layers, num of neurons per layer, num of output.\r\n","    self.szInp=szInp\r\n","    self.hiddenL=hiddenL\r\n","    self.numOp=numOp\r\n","    self.actvfunc=actvfunc\r\n","    self.initfunc=initfunc\r\n","    self.lossfunc=lossfunc\r\n","    self.lmda=lmda\r\n","    self.vx=vx\r\n","    self.vy=vy\r\n","    self.xtest=xtest\r\n","    self.ytest=ytest\r\n","    \r\n","    self.genericLayer=[szInp]+hiddenL+[numOp]\r\n","    print(\"Architechture of Neural Network (including i/p and o/p layer) \",self.genericLayer)\r\n","    \r\n","\r\n","    \r\n","    self.weights = []\r\n","\r\n","    if self.initfunc==\"random\":\r\n","      for i in range(len(self.genericLayer) - 1):\r\n","        w = np.random.random((self.genericLayer[i], self.genericLayer[i + 1]))\r\n","        (self.weights).append(w)\r\n","    elif self.initfunc==\"xavier\":\r\n","      for i in range(len(self.genericLayer) - 1):\r\n","        w = np.random.normal(0, 1/np.sqrt(self.genericLayer[i]), (self.genericLayer[i], self.genericLayer[i + 1]))\r\n","        (self.weights).append(w)\r\n","\r\n","    \r\n","\r\n","    self.biases=[]\r\n","    for i in range(len(self.genericLayer) - 1):\r\n","      b = np.random.normal(0, 1, self.genericLayer[i + 1])\r\n","      (self.biases).append(b)\r\n","\r\n","    self.activations = []\r\n","    for i in range(len(self.genericLayer)):\r\n","      a = np.zeros(self.genericLayer[i])\r\n","      (self.activations).append(a)    \r\n","\r\n","  def calculate_a_i(self, i, w):\r\n","    return np.dot(i,w)\r\n","\r\n","  sigmoid = lambda self, pa: np.array([(np.exp(term) if term<0 else 1)/(1+np.exp(term if term<0 else -term)) for term in pa])\r\n","  tanh = lambda self, pa: (np.exp(pa-np.max(pa))-np.exp(-pa-np.max(pa)))/(np.exp(pa-np.max(pa))+np.exp(-pa-np.max(pa)))\r\n","  reLU = lambda self, pa: np.maximum(0,np.minimum(1e+200,pa))\r\n","\r\n","  def calculate_h_i(self,pa):\r\n","    if self.actvfunc==\"sigmoid\" : return self.sigmoid(pa) \r\n","    elif self.actvfunc==\"tanh\" :  return np.tanh(pa)\r\n","    elif self.actvfunc==\"reLU\" : return self.reLU(pa)+1e-8\r\n","    #return 1/(1+np.exp(-pa))\r\n","\r\n","  def softmax(self,outpa):\r\n","    mx=np.max(outpa)\r\n","    outpa=outpa-mx\r\n","    return np.exp(outpa)/np.sum(np.exp(outpa)+1e-9)\r\n","\r\n","\r\n","  def feedFrwd(self,curinp,ws,bs):\r\n","    self.activations[0]=curinp\r\n","    for i in range(len(ws)-1):\r\n","      preActv=self.calculate_a_i(curinp, ws[i])+bs[i]\r\n","      actv=self.calculate_h_i(preActv)\r\n","      self.activations[i+1]=actv\r\n","      curinp=actv\r\n","    outPreActv=np.dot(curinp, ws[-1])+bs[-1]\r\n","    outActv=self.softmax(outPreActv)\r\n","    self.activations[-1]=outActv\r\n","\r\n","\r\n","  def justForwarding(self, xs):\r\n","      print(\"Weights and biases are initialised using \"+self.initfunc+\" and activation function is \"+self.actvfunc+\r\n","            \".\\nJust doing one time forward propagation(without back-propagation) for each data point.\\nTaking first 20 data points.\")\r\n","      for i in range(len(xs)):\r\n","        curinp=xs[i]\r\n","        self.feedFrwd(curinp,self.weights, self.biases)\r\n","        print(\"For point \",str(i+1),\" Outputting a probability distribution over the 10 classes. \",self.activations[-1],\".\\nPredicted class \", np.argmax(self.activations[-1]))\r\n","\r\n","\r\n","## main(){}//\r\n","obj=MLSN(dim_inp, [16, 32], 10, \"sigmoid\", \"xavier\", \"crossentropy\", 0.0002, valx, valy, testx, testy)# activ func, initialztn,\r\n","obj.justForwarding(trainx[0:20])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Architechture of Neural Network (including i/p and o/p layer)  [784, 16, 32, 10]\n","Weights and biases are initialised using xavier and activation function is sigmoid.\n","Just doing one time forward propagation(without back-propagation) for each data point.\n","\n","For point  1  Outputting a probability distribution over the 10 classes.  [0.05630292 0.074045   0.13077432 0.02065669 0.21122704 0.02762814\n"," 0.13130758 0.06412068 0.13593174 0.14800587] .\n","Predicted class  4\n","For point  2  Outputting a probability distribution over the 10 classes.  [0.05653563 0.07442449 0.13061673 0.02081382 0.20840086 0.02761842\n"," 0.12949204 0.06496514 0.13757779 0.14955507] .\n","Predicted class  4\n","For point  3  Outputting a probability distribution over the 10 classes.  [0.05714137 0.07327354 0.13042444 0.02119027 0.20692053 0.02732322\n"," 0.13110683 0.06467064 0.13802592 0.14992324] .\n","Predicted class  4\n","For point  4  Outputting a probability distribution over the 10 classes.  [0.05701879 0.07389544 0.13034308 0.02107149 0.20816189 0.02722057\n"," 0.13072568 0.06498629 0.13730228 0.1492745 ] .\n","Predicted class  4\n","For point  5  Outputting a probability distribution over the 10 classes.  [0.05693593 0.07393744 0.13070586 0.02093333 0.20811547 0.02729156\n"," 0.13083312 0.06442173 0.13843871 0.14838684] .\n","Predicted class  4\n","For point  6  Outputting a probability distribution over the 10 classes.  [0.05731085 0.07367454 0.13008039 0.0209854  0.20816522 0.02716106\n"," 0.13107886 0.06462434 0.13911402 0.14780531] .\n","Predicted class  4\n","For point  7  Outputting a probability distribution over the 10 classes.  [0.05732439 0.07370625 0.13132766 0.02085224 0.20681234 0.02758809\n"," 0.13153809 0.0640946  0.13720545 0.1495509 ] .\n","Predicted class  4\n","For point  8  Outputting a probability distribution over the 10 classes.  [0.05738211 0.07402963 0.13176595 0.02078789 0.20576459 0.02807938\n"," 0.12973748 0.06367491 0.13820387 0.15057418] .\n","Predicted class  4\n","For point  9  Outputting a probability distribution over the 10 classes.  [0.05811516 0.07224564 0.13238497 0.02118601 0.20443225 0.02776362\n"," 0.12985026 0.06350576 0.13934613 0.15117021] .\n","Predicted class  4\n","For point  10  Outputting a probability distribution over the 10 classes.  [0.05704475 0.07390278 0.13150485 0.02109141 0.20660162 0.02718713\n"," 0.13141452 0.06386023 0.13821113 0.14918159] .\n","Predicted class  4\n","For point  11  Outputting a probability distribution over the 10 classes.  [0.0570137  0.07346066 0.13189259 0.02113276 0.20670982 0.02770979\n"," 0.12817416 0.06476417 0.13970149 0.14944087] .\n","Predicted class  4\n","For point  12  Outputting a probability distribution over the 10 classes.  [0.05822938 0.07190568 0.13017032 0.02154597 0.20321582 0.02738801\n"," 0.13341451 0.06356938 0.13776805 0.15279288] .\n","Predicted class  4\n","For point  13  Outputting a probability distribution over the 10 classes.  [0.05749298 0.07353815 0.13203153 0.02097519 0.20690848 0.02776436\n"," 0.13004451 0.06325904 0.13762354 0.15036222] .\n","Predicted class  4\n","For point  14  Outputting a probability distribution over the 10 classes.  [0.05597726 0.07565287 0.1313673  0.02122435 0.20814002 0.02726016\n"," 0.12694896 0.06648051 0.13918059 0.14776798] .\n","Predicted class  4\n","For point  15  Outputting a probability distribution over the 10 classes.  [0.057562   0.072709   0.13135962 0.02115105 0.20686138 0.02720356\n"," 0.13217469 0.06342305 0.13828684 0.14926881] .\n","Predicted class  4\n","For point  16  Outputting a probability distribution over the 10 classes.  [0.05621666 0.07468158 0.13211708 0.02085841 0.20700433 0.02789533\n"," 0.12737142 0.06512416 0.13929925 0.14943178] .\n","Predicted class  4\n","For point  17  Outputting a probability distribution over the 10 classes.  [0.05701232 0.07341559 0.13018986 0.02148325 0.20786568 0.02709286\n"," 0.13053772 0.06514906 0.13777929 0.14947438] .\n","Predicted class  4\n","For point  18  Outputting a probability distribution over the 10 classes.  [0.05655388 0.0743092  0.13361921 0.02089464 0.20686493 0.02806055\n"," 0.12489058 0.06523512 0.14028454 0.14928734] .\n","Predicted class  4\n","For point  19  Outputting a probability distribution over the 10 classes.  [0.05730367 0.07289654 0.13224127 0.02093184 0.20791009 0.02767324\n"," 0.12966525 0.06420346 0.13828626 0.14888837] .\n","Predicted class  4\n","For point  20  Outputting a probability distribution over the 10 classes.  [0.05825857 0.07197813 0.13255213 0.02117233 0.20460235 0.02765072\n"," 0.13113058 0.06330625 0.13855729 0.15079165] .\n","Predicted class  4\n"],"name":"stdout"}]}]}