{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ASSGN_2(Part-A_Ques-2).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"4YifRN01NuG0"},"source":["## Author- Sayan Chandra\n","## Roll - CS20M057\n","## Instructor - Mitesh M. Khapra\n","## Course - CS6910 (Fundamentals of Deep Learning)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dgpRi_ydDyA","executionInfo":{"status":"ok","timestamp":1618421808801,"user_tz":-330,"elapsed":1556,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}}},"source":["WANDB=0"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5mcz8weeVeC","executionInfo":{"status":"ok","timestamp":1618421809429,"user_tz":-330,"elapsed":1609,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}}},"source":["if WANDB:\n","  !pip install wandb"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJ19WI3Xeyge","executionInfo":{"status":"ok","timestamp":1618421847599,"user_tz":-330,"elapsed":1088,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}}},"source":["if WANDB:\n","  !wandb login #952756aa88ee3a472980bceb7d23632ac0a85500"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJnm93xle3JW","executionInfo":{"status":"ok","timestamp":1618421848413,"user_tz":-330,"elapsed":1141,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}}},"source":["if WANDB:\n","  import wandb"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"gR9Ser5sR9rk"},"source":["## importing all necessary modules\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","\n","import torch\n","import torch.nn as cnn\n","import torch.optim as optimisations\n","from torch.nn import functional as func\n","from torch.utils.data import DataLoader as dataloader\n","import torchvision.transforms as transforms\n","import torchvision\n","from torch.autograd import Variable\n","import gc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSNPU2ieuUAx"},"source":["!pip install split-folders\n","import splitfolders as sf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fENBBt8Wfn4Y"},"source":["!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n","!unzip nature_12K.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyftVx7ZwhlZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618377503475,"user_tz":-330,"elapsed":53943,"user":{"displayName":"Sayan Chandra cs20m057","photoUrl":"","userId":"12052533651248196767"}},"outputId":"807509f1-87b5-4f3f-ea97-3579d03290ce"},"source":["MAINPATH = \"/content/inaturalist_12K/\"\n","sf.fixed(MAINPATH + \"train\", output=MAINPATH+\"train_split\", seed=1337, fixed=100, oversample=False, group_prefix=None)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Copying files: 9999 files [00:52, 190.64 files/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KTKsuWWS-hDG"},"source":["sizew=224; sizeh=224\n","data_transforms = transforms.Compose([\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6sNPLKmS_zH"},"source":["def loadTrain_Val_TestData(BATCH_SIZE): # no arguments\n","  TESTPATH=\"/content/inaturalist_12K/val\"\n","  train_data = torchvision.datasets.ImageFolder(root=MAINPATH+\"train_split/train/\", transform=data_transforms)\n","  val_data = torchvision.datasets.ImageFolder(root=MAINPATH+\"train_split/val/\", transform=data_transforms)\n","  train_data_loader = dataloader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=1)\n","  val_data_loader = dataloader(val_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=1)\n","  test_data = torchvision.datasets.ImageFolder(root=TESTPATH, transform=data_transforms)\n","  test_data_loader  = dataloader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=1)\n","  return train_data, test_data, val_data, train_data_loader, test_data_loader, val_data_loader\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dg8siwjt3Iyc"},"source":["sweep_config={\n","    'method' : 'bayes',\n","    'metric' : {\n","        'name' : 'Val Accuracy',\n","        'goal' : 'maximize',\n","    },\n","    'parameters' : {\n","        'epochs' : {\n","            'values' : [7, 10, 15],\n","        },\n","        'batch_size' : {\n","            'values' : [8, 16, 32],\n","        },\n","        'out_layer_size' : {\n","            'values' : [[32, 64, 128, 256, 512], [256, 128, 64, 32, 16], [64, 64, 64, 64, 64], [128, 128, 256, 256, 512], [64, 64, 32, 32, 32], [64, 64, 64, 32, 32]],\n","        },\n","        'convkernel' : {\n","            'values' : [[7, 7, 5, 5, 3],  [5, 5, 3, 3, 3], [11, 7, 7, 5, 3]]\n","        },\n","        'convstride' : {\n","            'values' : [[1,1,1,1,1], [1, 1, 1, 2, 2], [2, 2, 2, 1, 1]]\n","        },\n","        'poolkernel' : {\n","            'values' : [[2, 2, 2, 2, 2], [3, 3, 3, 2, 2]]\n","        },\n","        'poolstride' : {\n","            'values' : [[1, 2, 2, 2, 2], [1, 2, 1, 2, 1], [1, 1, 1, 1, 1]]\n","        },\n","        'denselayer' : {\n","            'values' : [ 32, 64, 128]\n","        },\n","        'learning_rate' : {\n","            'values' : [0.001, 0.002, 1.7e-4, 2.2e-4, 2.2e-5, 0.0014, 0.0022, 1.5e-5],\n","        },\n","        'batchnorm' : {\n","            'values' : [1, 0]\n","        },\n","        'dropout' : {\n","            'values' : [0.5, 0.25, 0.1, 0.2]\n","        },\n","        'weightdecay' : {\n","            'values' : [0, 0.00001, 0.00002]\n","        }\n","    }\n","}\n"," if WANDB: sweep_id = wandb.sweep(sweep_config, entity=\"blackcloud\", project=\"cs6910_dl_assignment_2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3hCmhtJQUt0"},"source":["\n","\n","numOfConvPoolLayers=5\n","sizew=224; sizeh=224\n","def computeFirstDenseLayer(cnn_config):\n","  #print(cnn_config, 1)\n","  w,h,d=sizew,sizeh,3\n","  for i in range( numOfConvPoolLayers):\n","    d=cnn_config[i][1]\n","    w=1+np.floor((w-cnn_config[i][2]+2* cnn_config[i][4])/cnn_config[i][3])\n","    w=1+np.floor((w-cnn_config[i][5])/cnn_config[i][6])\n","    h=w #1+np.floor((h-cnn_config[i][5])/cnn_config[i][6])\n","  #print(w,h,d)  \n","  return w*h*d\n","#print(computeFirstDenseLayer(cnn_config))\n","def getconfig(out_layer_size, convkernel, convstride, poolkernel, poolstride):\n","  #print(2)\n","  in_layer_size=[3]+out_layer_size[:-1]\n","  padding=[0 for _ in range (numOfConvPoolLayers)]\n","  cnn_config=[in_layer_size, out_layer_size, convkernel, convstride, padding, poolkernel, poolstride]\n","  ret=np.transpose(cnn_config)\n","  print('the cnn_config is ',ret)\n","  return ret"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Qk9ciuqAC1H"},"source":["class CNN(cnn.Module):\n","  def __init__(self, cnn_config, in_channels=3, num_classes=10, denselayer=64, prob=0.2):\n","    super(CNN, self).__init__()\n","    #print(cnn_config, 3)\n","\n","    self.conv1=cnn.Conv2d(in_channels=cnn_config[0][0], out_channels=cnn_config[0][1], kernel_size= cnn_config[0][2], stride= cnn_config[0][3], padding= cnn_config[0][4])\n","    cnn.init.xavier_uniform_(self.conv1.weight)\n","    self.activ=self.Activ2d(\"relu\")\n","    self.batchnorm1=cnn.BatchNorm2d(cnn_config[0][1])\n","    self.maxpool1=cnn.MaxPool2d(cnn_config[0][5], stride=cnn_config[0][6])\n","\n","    self.conv2=cnn.Conv2d(in_channels=cnn_config[1][0], out_channels=cnn_config[1][1], kernel_size= cnn_config[1][2], stride= cnn_config[1][3], padding= cnn_config[1][4])\n","    cnn.init.xavier_uniform_(self.conv2.weight)\n","    self.batchnorm2=cnn.BatchNorm2d(cnn_config[1][1])\n","    self.maxpool2=cnn.MaxPool2d(cnn_config[1][5], stride=cnn_config[1][6])\n","    \n","    self.conv3=cnn.Conv2d(in_channels=cnn_config[2][0], out_channels=cnn_config[2][1], kernel_size= cnn_config[2][2], stride= cnn_config[2][3], padding= cnn_config[2][4])\n","    cnn.init.xavier_uniform_(self.conv3.weight)\n","    self.batchnorm3=cnn.BatchNorm2d(cnn_config[2][1])\n","    self.maxpool3=cnn.MaxPool2d(cnn_config[2][5], stride=cnn_config[2][6])\n","\n","    self.conv4=cnn.Conv2d(in_channels=cnn_config[3][0], out_channels=cnn_config[3][1], kernel_size= cnn_config[3][2], stride= cnn_config[3][3], padding= cnn_config[3][4])\n","    cnn.init.xavier_uniform_(self.conv4.weight)\n","    self.batchnorm4=cnn.BatchNorm2d(cnn_config[3][1])\n","    self.maxpool4=cnn.MaxPool2d(cnn_config[3][5], stride=cnn_config[3][6])\n","\n","    self.conv5=cnn.Conv2d(in_channels=cnn_config[4][0], out_channels=cnn_config[4][1], kernel_size= cnn_config[4][2], stride= cnn_config[4][3], padding= cnn_config[4][4])\n","    cnn.init.xavier_uniform_(self.conv5.weight)\n","    self.batchnorm5=cnn.BatchNorm2d(cnn_config[4][1])\n","    self.maxpool5=cnn.MaxPool2d(cnn_config[4][5], stride=cnn_config[4][6])\n","    \n","    self.val=computeFirstDenseLayer(cnn_config).astype(int)\n","    self.fullconn1=cnn.Linear(in_features=self.val, out_features= denselayer)\n","    cnn.init.xavier_uniform_(self.fullconn1.weight)\n","    self.dropout=cnn.Dropout(p=prob)\n","    self.output=cnn.Linear(in_features= denselayer, out_features= num_classes)\n","\n","  def forward(self, curinp, bn=0):\n","    out=curinp\n","    if bn:\n","        out=self.maxpool1(self.batchnorm1(self.activ(self.conv1(out))))\n","        out=self.maxpool2(self.batchnorm2(self.activ(self.conv2(out))))\n","        out=self.maxpool3(self.batchnorm3(self.activ(self.conv3(out))))\n","        out=self.maxpool4(self.batchnorm4(self.activ(self.conv4(out))))\n","        out=self.maxpool5(self.batchnorm5(self.activ(self.conv5(out)))) #self.batchnorm5(\n","\n","\n","    else:\n","        out=self.maxpool1(self.activ(self.conv1(out)))\n","        out=self.maxpool2(self.activ(self.conv2(out)))\n","        out=self.maxpool3(self.activ(self.conv3(out)))\n","        out=self.maxpool4(self.activ(self.conv4(out)))\n","        out=self.maxpool5(self.activ(self.conv5(out))) #self.batchnorm5(\n","\n","    out=out.view(-1, self.val)\n","    out=self.activ(self.fullconn1(out))\n","    out=self.dropout(out)\n","    out=func.softmax(self.output(out), dim=1) \n","    return out\n","\n","  def Activ2d(self, str):\n","    if str==\"relu\" : return func.relu\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Uv_4rpicuua"},"source":["def accuracyAndLoss(data_loader, cnnModel, heyGPU, optimizer, scheduler, bn, lossfunc) :\n","      predictedright=0\n","      totalimgs=0\n","      globalloss=0\n","      with torch.no_grad():\n","          for img, y in data_loader:\n","              if heyGPU : img, y=Variable(img.cuda()), Variable(y.cuda())\n","              else : img, y=Variable(img), Variable(y)\n","              outp=cnnModel(img, bn)\n","              curloss=lossfunc(outp, y)\n","              globalloss+=curloss\n","              ignore, predicted = torch.max(outp.data, 1)\n","              totalimgs+=y.size(0)\n","              if heyGPU : predictedright+=(predicted.cpu()==y.cpu()).sum()\n","              else : predictedright+=(predicted==y).sum()\n","      curaccuracy=(predictedright/totalimgs)*100\n","      del predictedright, totalimgs\n","      return curaccuracy.item(), globalloss.item()/1000 \n","def trainMyModel(EPOCHS, cnnModel, train_data_loader, heyGPU, optimizer, scheduler, val_data_loader, bn, lossfunc):\n","    for run in range(EPOCHS):\n","      globalloss=0\n","      cnnModel.train(True)\n","      for i, (curimg, ytrue) in enumerate(train_data_loader):\n","        if heyGPU : curimg, ytrue=Variable(curimg.cuda()), Variable(ytrue.cuda())\n","        else : curimg, ytrue=Variable(curimg), Variable(ytrue)\n","        #print(\"yoo\")\n","        optimizer.zero_grad()\n","        outputt=cnnModel(curimg, bn)\n","        curloss=lossfunc(outputt, ytrue)\n","        globalloss+=curloss\n","        curloss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        #print(\"yooy\")\n","\n","      c, d=accuracyAndLoss(val_data_loader, cnnModel, heyGPU, optimizer, scheduler, bn, lossfunc)  \n","\n","      print(\"epochs: \",run, \"Training loss: \", globalloss/8999, \"val accuracy+loss \", c, d)\n","      if WABDB: wandb.log({\"epochs\":run, \"Training loss\":globalloss.item()/8999, \"Val Accuracy\":c, \"Val Loss\":d})\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XpjFOOS1JUym"},"source":["gc.collect()\n","torch.cuda.empty_cache()\n","def SweepParent():\n","       if WANDB:\n","              start=wandb.init()\n","              config=start.config\n","              bsz=config.batch_size\n","              train_data, test_data, val_data, train_data_loader, test_data_loader, val_data_loader = loadTrain_Val_TestData(bsz)\n","              ols=config.out_layer_size\n","              cnn_config=getconfig(ols, config.convkernel, config.convstride, config.poolkernel, config.poolstride)\n","              cnnModel=CNN(cnn_config, denselayer=config.denselayer, p=config.dropout)\n","              heyGPU=torch.cuda.is_available()\n","              if heyGPU: cnnModel=cnnModel.cuda()\n","              lossfunc=cnn.CrossEntropyLoss()\n","              print(heyGPU)\n","              #optimizer=optimisations.Adam(cnnModel.parameters(), lr=0.006)\n","              #optimizer=optimisations.AdamW(cnnModel.parameters(), lr=0.001, weight_decay=0.005)\n","              optimizer = torch.optim.SGD(cnnModel.parameters(), lr=config.learning_rate, momentum=0.92, weight_decay=config.weightdecay)\n","              scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(np.ceil(len(train_data_loader)/bsz)))\n","              epk=config.epochs\n","              if ols==[256, 128, 64, 32, 16] : epk=5\n","              trainMyModel(epk, cnnModel, train_data_loader, heyGPU, optimizer, scheduler, val_data_loader, config.batchnorm, lossfunc)\n","              del cnnModel\n","              del optimizer, scheduler, epk, ols, heyGPU, bsz, start, config\n","              gc.collect()\n","              torch.cuda.empty_cache()\n","       else:\n","              bsz=64\n","              train_data, test_data, val_data, train_data_loader, test_data_loader, val_data_loader = loadTrain_Val_TestData(bsz)\n","              cnn_config=[[3, 64, 11, 2, 0, 2, 1],\n","                          [64, 64, 7, 2, 0, 2, 1],\n","                          [64, 32, 5, 2, 0, 2, 1],\n","                          [32, 32, 3, 1, 0, 2, 1],\n","                          [32, 32, 3, 1, 0, 2, 1]]\n","              cnnModel=CNN(cnn_config, denselayer=64, prob=0.2)\n","              heyGPU=torch.cuda.is_available()\n","              if heyGPU: cnnModel=cnnModel.cuda()\n","              lossfunc=cnn.CrossEntropyLoss()\n","              print(heyGPU)\n","              #optimizer=optimisations.Adam(cnnModel.parameters(), lr=0.006)\n","              #optimizer=optimisations.AdamW(cnnModel.parameters(), lr=0.001, weight_decay=0.005)\n","              optimizer = torch.optim.SGD(cnnModel.parameters(), 0.0022, momentum=0.94, weight_decay=0)\n","              scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(np.ceil(len(train_data_loader)/bsz)))\n","              epk=15 ; lossfunc=cnn.CrossEntropyLoss()\n","              trainMyModel(epk, cnnModel, train_data_loader, heyGPU, optimizer, scheduler, val_data_loader, 1, lossfunc)\n","              del cnnModel\n","              del optimizer, scheduler, epk, ols, heyGPU, bsz, start, config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mq8yJeFzKWoB"},"source":["if WANDB: wandb.agent(sweep_id, SweepParent)\n","else: SweepParent()"],"execution_count":null,"outputs":[]}]}